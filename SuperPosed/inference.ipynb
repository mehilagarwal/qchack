{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "optical-turkish",
   "metadata": {},
   "source": [
    "## Digit Inference based on QML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "talented-philippines",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.transform import resize\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "contemporary-coverage",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_bacak_vqc(eval_count, var_params, eval_val, index):\n",
    "    print(\"eval_count: {}\".format(eval_count))\n",
    "    print(\"var_params: {}\".format(var_params))\n",
    "    print(\"evl_val: {}\".format(eval_val))\n",
    "    print(\"index: {}\".format(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "empirical-lesson",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_dir = './models'\n",
    "model_0_3_5_6_8 = pickle.load(open(f'{models_dir}/model_0_3_5_6_8','rb'))\n",
    "model_0 = pickle.load(open(f'{models_dir}/model_0','rb'))\n",
    "model_4 = pickle.load(open(f'{models_dir}/model_4','rb'))\n",
    "model_5 = pickle.load(open(f'{models_dir}/model_5','rb'))\n",
    "model_3_8 = pickle.load(open(f'{models_dir}/model_3_8','rb'))\n",
    "model_3 = pickle.load(open(f'{models_dir}/model_3','rb'))\n",
    "model_1_2 = pickle.load(open(f'{models_dir}/model_1_2','rb'))\n",
    "model_1 = pickle.load(open(f'{models_dir}/model_1','rb'))\n",
    "model_4_9 = pickle.load(open(f'{models_dir}/model_4_9','rb'))\n",
    "# tsvd = pickle.load(open(f'{models_dir}/tsvd_transforms.pkl','rb'))\n",
    "# um = pickle.load(open(f'{models_dir}/umap_transforms.pkl','rb'))\n",
    "data_path = \"./\"\n",
    "train_data = np.loadtxt(data_path + \"mnist_train.csv\", delimiter=\",\")\n",
    "train_data_features = train_data[:10000, 1:]\n",
    "tsvd = TruncatedSVD(n_components=20)\n",
    "X_SVD = tsvd.fit_transform(train_data_features)\n",
    "um = umap.UMAP()\n",
    "_ = um.fit_transform(X_SVD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "raising-cursor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<qiskit.aqua.algorithms.classifiers.vqc.VQC at 0x26ad63e4af0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_0_3_5_6_8.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "vital-leather",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import *\n",
    "\n",
    "def run_model(model,data):\n",
    "    backend = BasicAer.get_backend(backend_value)\n",
    "    if(backend_value=='IBMQ'):\n",
    "        IBMQ.load_account()\n",
    "        provider = IBMQ.get_provider(hub='ibm-q')\n",
    "        backend = least_busy(provider.backends(filters=lambda x: x.configuration().n_qubits >= (n+1) and\n",
    "                                       not x.configuration().simulator and x.status().operational==True))\n",
    "#         print(\"least busy backend: \", backend)\n",
    "    model.backend = backend\n",
    "    model.predict(data)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "def remove_padding(img):\n",
    "    top_border = 0\n",
    "    bot_border = img.shape[0]-1\n",
    "    left_border = 0\n",
    "    right_border = img.shape[1]-1\n",
    "    for i in range(img.shape[0]):\n",
    "        if(sum(img[i])!=0):\n",
    "            top_border = i\n",
    "            break\n",
    "    for i in range(img.shape[0]-1,-1,-1):\n",
    "        if(sum(img[i])!=0):\n",
    "            bot_border = i\n",
    "            break\n",
    "            \n",
    "    for i in range(img.shape[1]):\n",
    "        if(sum(img[:,i])!=0):\n",
    "            left_border = i\n",
    "            break\n",
    "    for i in range(img.shape[1]-1,-1,-1):\n",
    "        if(sum(img[:,i])!=0):\n",
    "            right_border = i\n",
    "            break\n",
    "    return img[top_border:bot_border,left_border:right_border]\n",
    "    \n",
    "    \n",
    "def pre_process(img):\n",
    "    img = remove_padding(img)\n",
    "    img = resize(img, (24, 24))\n",
    "    img_bl = np.zeros((28,28))\n",
    "    img_bl[2:26,2:26] = img\n",
    "    img = img_bl\n",
    "    \n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            img[i][j] = img[i][j] if img[i][j]<1 else 255\n",
    "\n",
    "    flat = img.reshape(784,)\n",
    "\n",
    "    # Apply Dimensionality Reduction\n",
    "\n",
    "    X1 = tsvd.transform([flat])\n",
    "    X2 = um.transform(X1)\n",
    "    \n",
    "    return X2\n",
    "    \n",
    "def predict(img):\n",
    "    img = pre_process(img)\n",
    "    pred = run_model(model_0_3_5_6_8,img)\n",
    "    if(pred==1):\n",
    "        pred = run_model(model_1_2,img)\n",
    "        if(pred==1):\n",
    "            pred = run_model(model_4_9,img)\n",
    "            if(pred==1):\n",
    "                return 7\n",
    "            else:\n",
    "                pred = run_model(model_4,img)\n",
    "                return 4 if pred==0 else 9\n",
    "        else:\n",
    "            pred = run_model(model_1,img)\n",
    "            return 1 if pred==0 else 2\n",
    "    else:\n",
    "        pred = run_model(model_3_8,img)\n",
    "        if(pred==1):\n",
    "            pred = run_model(model_5,img)\n",
    "            if(pred==1):\n",
    "                pred = run_model(model_0,img)\n",
    "                return 0 if pred==0 else 6\n",
    "            else:\n",
    "                return 5\n",
    "        else:\n",
    "            pred = run_model(model_3,img)\n",
    "            return 3 if pred==0 else 8\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "narrative-spread",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffa5a250a9a94ce3a497a31987bc5e9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "RadioButtons(description='Choose Backend', options=('qasm_simulator', 'statevector_simulator', 'IBMQ'), value=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import jupyter_drawing_pad as jd\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "\n",
    "radio_widget = widgets.RadioButtons(\n",
    "    options=['qasm_simulator', 'statevector_simulator', 'IBMQ'],\n",
    "    description='Choose Backend',\n",
    "    disabled=False\n",
    ")\n",
    "radio_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "settled-discussion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aff889d0ab5e45619f0221c27c3a0b0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CustomBox(children=(DrawingPad(data=[[], [], []]), VBox(children=(Text(value='', description='Name:', placehol…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "widget = jd.CustomBox()\n",
    "canvas_dim = (500,250)\n",
    "image_dim = (250,250)\n",
    "backend_value = radio_widget.value\n",
    "widget\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "immune-concord",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(canvas_data):\n",
    "    image = np.zeros(image_dim)\n",
    "    n = len(canvas_data[0])\n",
    "    max_intensity = max(canvas_data[2])\n",
    "    \n",
    "    for i in range(n):\n",
    "        x,y = int(canvas_data[0][i]/canvas_dim[0] * image_dim[0]), int(canvas_data[1][i]/canvas_dim[1] * image_dim[1])\n",
    "        value = float(canvas_data[2][i])/float(max_intensity) * 255.0\n",
    "        image[x][y] = value\n",
    "#         print(f\"{x},{y} : {value}\")\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "informational-savings",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You typed: 8\n"
     ]
    }
   ],
   "source": [
    "num = predict(get_image(widget.drawing_pad.data))\n",
    "print('You typed:',num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "framed-reservoir",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
